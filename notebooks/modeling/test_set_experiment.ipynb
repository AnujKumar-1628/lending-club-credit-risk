{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc14731",
   "metadata": {},
   "source": [
    "## Test Set Evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "473b0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure repo root is importable when running from notebooks/\n",
    "repo_root = Path.cwd()\n",
    "while not (repo_root / 'src').exists() and repo_root.parent != repo_root:\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "if not (repo_root / 'src').exists():\n",
    "    raise RuntimeError('Could not locate project root from current working directory.')\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.append(str(repo_root))\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from credit_risk.data.load_data import load_cleaned_data\n",
    "from credit_risk.data.split_data import DataSplitter\n",
    "from credit_risk.evaluation.metrics import evaluate_classification\n",
    "from credit_risk.features.build_features import FeatureBuilder\n",
    "from credit_risk.utils.config import data_config, split_config, xgb_config\n",
    "from credit_risk.utils.logging import get_logger\n",
    "from credit_risk.utils.paths import project_root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "976eb940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:53:51 | INFO | test_set_experiment | Project root: D:\\Projects\\lending-club-credit-risk\n",
      "2026-02-17 15:53:51 | INFO | test_set_experiment | Split config -> train=0.70, val=0.15, test=0.15\n",
      "2026-02-17 15:53:51 | INFO | test_set_experiment | Target column: is_default\n",
      "2026-02-17 15:53:51 | INFO | test_set_experiment | XGBoost eval metric from config: auc\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger('test_set_experiment')\n",
    "logger.info(f'Project root: {project_root}')\n",
    "logger.info(\n",
    "    f'Split config -> train={split_config.TRAIN_FRAC:.2f}, val={split_config.VAL_FRAC:.2f}, test={1 - split_config.TRAIN_FRAC - split_config.VAL_FRAC:.2f}'\n",
    ")\n",
    "logger.info(f'Target column: {data_config.TARGET_COL}')\n",
    "logger.info(f'XGBoost eval metric from config: {xgb_config.PARAMS[\"eval_metric\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b31ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:53:59 | INFO | test_set_experiment | Loading cleaned dataset\n",
      "2026-02-17 15:53:59 | INFO | credit_risk.data.load_data | Loading cleaned data from D:\\Projects\\lending-club-credit-risk\\data\\processed\\cleaned_data.parquet\n",
      "2026-02-17 15:54:01 | INFO | credit_risk.data.load_data | Cleaned data shape: (1345309, 30)\n",
      "2026-02-17 15:54:02 | INFO | credit_risk.data.split_data | Split sizes â†’ train=941716, val=201796, test=201797\n",
      "2026-02-17 15:54:02 | INFO | test_set_experiment | Train shape: (941716, 30)\n",
      "2026-02-17 15:54:02 | INFO | test_set_experiment | Validation shape: (201796, 30)\n",
      "2026-02-17 15:54:02 | INFO | test_set_experiment | Test shape: (201797, 30)\n"
     ]
    }
   ],
   "source": [
    "logger.info('Loading cleaned dataset')\n",
    "df = load_cleaned_data()\n",
    "\n",
    "splitter = DataSplitter()\n",
    "train_df, val_df, test_df = splitter.split(df)\n",
    "\n",
    "logger.info(f'Train shape: {train_df.shape}')\n",
    "logger.info(f'Validation shape: {val_df.shape}')\n",
    "logger.info(f'Test shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "761b431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:54:05 | INFO | test_set_experiment | Loading trained model artifacts\n",
      "2026-02-17 15:54:05 | INFO | test_set_experiment | Models loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\lending-club-credit-risk\\venv\\Lib\\site-packages\\sklearn\\base.py:463: InconsistentVersionWarning: Trying to unpickle estimator SGDClassifier from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LOGISTIC_MODEL_PATH = project_root / 'models' / 'logistic' / 'model.pkl'\n",
    "XGBOOST_MODEL_PATH = project_root / 'models' / 'xgboost' / 'model.pkl'\n",
    "\n",
    "required = [LOGISTIC_MODEL_PATH, XGBOOST_MODEL_PATH]\n",
    "missing = [str(p) for p in required if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError('Missing model artifacts:\\n' + '\\n'.join(missing))\n",
    "\n",
    "logger.info('Loading trained model artifacts')\n",
    "logistic_model = joblib.load(LOGISTIC_MODEL_PATH)\n",
    "xgb_model = joblib.load(XGBOOST_MODEL_PATH)\n",
    "logger.info('Models loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7101bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:54:08 | INFO | credit_risk.features.build_features | Building features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\lending-club-credit-risk\\src\\credit_risk\\features\\build_features.py:56: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"earliest_cr_line\"] = pd.to_datetime(df[\"earliest_cr_line\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:54:17 | INFO | credit_risk.features.build_features | Building features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\lending-club-credit-risk\\src\\credit_risk\\features\\build_features.py:56: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"earliest_cr_line\"] = pd.to_datetime(df[\"earliest_cr_line\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:54:19 | INFO | test_set_experiment | Test feature matrix shape: (201797, 135)\n",
      "2026-02-17 15:54:19 | INFO | test_set_experiment | Test target size: 201797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_builder = FeatureBuilder()\n",
    "_ = feature_builder.build_features(train_df, fit=True)\n",
    "X_test, y_test = feature_builder.build_features(test_df, fit=False)\n",
    "\n",
    "logger.info(f'Test feature matrix shape: {X_test.shape}')\n",
    "logger.info(f'Test target size: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0f645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-17 15:54:24 | INFO | test_set_experiment | Logistic_SGD | test ROC-AUC=0.6974, KS=0.2859\n",
      "2026-02-17 15:54:25 | INFO | test_set_experiment | XGBoost | test ROC-AUC=0.7096, KS=0.3038\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model_name, model, X, y, threshold=0.5):\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    metrics = evaluate_classification(y_true=y, y_prob=y_prob, threshold=threshold)\n",
    "\n",
    "    logger.info(\n",
    "        f'{model_name} | test ROC-AUC={metrics[\"roc_auc\"]:.4f}, KS={metrics[\"ks\"]:.4f}'\n",
    "    )\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'split': 'test',\n",
    "        'roc_auc': metrics['roc_auc'],\n",
    "        'ks': metrics['ks'],\n",
    "        'confusion_matrix': metrics['confusion_matrix'],\n",
    "    }\n",
    "\n",
    "log_result = evaluate_model('Logistic_SGD', logistic_model, X_test, y_test, threshold=0.5)\n",
    "xgb_result = evaluate_model('XGBoost', xgb_model, X_test, y_test, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f740a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>ks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>test</td>\n",
       "      <td>0.709644</td>\n",
       "      <td>0.303781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic_SGD</td>\n",
       "      <td>test</td>\n",
       "      <td>0.697436</td>\n",
       "      <td>0.285869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model split   roc_auc        ks\n",
       "0       XGBoost  test  0.709644  0.303781\n",
       "1  Logistic_SGD  test  0.697436  0.285869"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([\n",
    "    {'model': log_result['model'], 'split': log_result['split'], 'roc_auc': log_result['roc_auc'], 'ks': log_result['ks']},\n",
    "    {'model': xgb_result['model'], 'split': xgb_result['split'], 'roc_auc': xgb_result['roc_auc'], 'ks': xgb_result['ks']},\n",
    "]).sort_values(by='roc_auc', ascending=False).reset_index(drop=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29cfbbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic confusion matrix:\n",
      "[[143300  15900]\n",
      " [ 31359  11238]]\n",
      "\n",
      "XGBoost confusion matrix:\n",
      "[[151515   7685]\n",
      " [ 35489   7108]]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic confusion matrix:')\n",
    "print(log_result['confusion_matrix'])\n",
    "\n",
    "print('\\nXGBoost confusion matrix:')\n",
    "print(xgb_result['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8afef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
